{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"00ad4a8f-5eb7-4388-810b-73790e67b268","_uuid":"154cfe46-76d6-4c81-a572-5b07428a0437","collapsed":false,"execution":{"iopub.execute_input":"2023-07-12T13:04:23.298870Z","iopub.status.busy":"2023-07-12T13:04:23.298500Z","iopub.status.idle":"2023-07-12T13:04:54.858303Z","shell.execute_reply":"2023-07-12T13:04:54.857135Z","shell.execute_reply.started":"2023-07-12T13:04:23.298840Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import sys\n","from copy import deepcopy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import time\n","import random\n","import gc\n","import pandas as pd\n","from collections import defaultdict\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch import Tensor\n","\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","from torch.nn.utils import weight_norm\n","\n","# import torch.distributed as dist\n","\n","# import torchopt\n","# import functorch\n","\n","import higher\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","os.environ['TF_FORCE_GPU_ALLOW_GROWTH']='true'\n","device"]},{"cell_type":"markdown","metadata":{"_cell_guid":"42bacbaa-7098-4479-82b6-9f1038354014","_uuid":"7ec89c21-2d9a-4f99-87ee-f67413220a51","trusted":true},"source":["# __*Parameters*__"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"15f152bc-c619-435e-8d99-288412c95158","_uuid":"63beb690-710c-4682-abfa-181ec654f06a","collapsed":false,"execution":{"iopub.execute_input":"2023-07-12T13:04:54.860853Z","iopub.status.busy":"2023-07-12T13:04:54.860447Z","iopub.status.idle":"2023-07-12T13:04:54.869347Z","shell.execute_reply":"2023-07-12T13:04:54.868332Z","shell.execute_reply.started":"2023-07-12T13:04:54.860812Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"data":{"text/plain":["1"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["world_size = torch.cuda.device_count() ## Number of GPU's available\n","\n","num_classes = 10                       ## Number of classes in the dataset\n","inner_loop_iterations = 32             ## Number of iterations in the inner training loop\n","\n","noise_size = 128                       ## Dimension of the noise vector used by the Generator\n","batch_size = 256                       ## Number of images in a batch in the inner loop\n","\n","use_curriculum = True                  ## Enables Curriculum Learning\n","\n","world_size"]},{"cell_type":"markdown","metadata":{"_cell_guid":"46b26ddd-efc1-48fb-bab3-07cd8277ba4a","_uuid":"35978341-9f91-47ba-8322-6acc72d53c34","trusted":true},"source":["# __*Importing Data*__"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"34ecf166-fc1a-498a-abe4-b6ad98ed9e7e","_uuid":"0fcd75b9-5b39-435a-9f7e-981d42e4398a","collapsed":false,"execution":{"iopub.execute_input":"2023-07-12T13:04:54.870906Z","iopub.status.busy":"2023-07-12T13:04:54.870380Z","iopub.status.idle":"2023-07-12T13:05:12.761183Z","shell.execute_reply":"2023-07-12T13:05:12.760209Z","shell.execute_reply.started":"2023-07-12T13:04:54.870874Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["transform = transforms.Compose([\n","    transforms.Lambda(lambda x: np.array(x)),\n","    transforms.ToTensor(),\n","#     torchvision.transforms.Resize((32,48),antialias=False),\n","    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n","])\n","\n","# train = datasets.MNIST('../data', train=True, transform=transform, download=True)\n","# train, val = torch.utils.data.random_split(train, [50000, 10000])\n","# test = datasets.MNIST('../data', train=False, transform=transform, download=True)\n","\n","\n","train = datasets.CIFAR10('../data', train=True, transform=transform, download=True)\n","train, val = torch.utils.data.random_split(train, [inner_loop_iterations * batch_size, 50000 - inner_loop_iterations * batch_size])\n","test = datasets.CIFAR10('../data', train=False, transform=transform, download=True)\n","\n","train = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle=True, drop_last=True)\n","val = torch.utils.data.DataLoader(val, batch_size = batch_size * 2, shuffle=True, drop_last=True)\n","test = torch.utils.data.DataLoader(test, batch_size = batch_size * 2, shuffle=True, drop_last=True)\n","\n","steps_per_epoch = len(val)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T13:05:12.764904Z","iopub.status.busy":"2023-07-12T13:05:12.764524Z","iopub.status.idle":"2023-07-12T13:05:12.869608Z","shell.execute_reply":"2023-07-12T13:05:12.868644Z","shell.execute_reply.started":"2023-07-12T13:05:12.764872Z"},"trusted":true},"outputs":[],"source":["import virtusagtn.Models as Models\n","import torchmetrics\n","mylearners = [Models.Learner(img_size=[3,32,32], num_classes=10,\n","                cnn_filters = np.random.randint(low=32, high=256, size=(3,)),\n","                linear_filters = np.random.randint(low=32, high=128, size=(1,)))\n","                for i in range(1)]"]},{"cell_type":"code","execution_count":10,"metadata":{"_cell_guid":"52b40d00-8315-49a3-a9c6-3ef917c318cb","_uuid":"db550f5f-84fd-4b1b-89f7-4bb925fd9dc4","collapsed":false,"execution":{"iopub.execute_input":"2023-07-12T13:06:29.966651Z","iopub.status.busy":"2023-07-12T13:06:29.965664Z","iopub.status.idle":"2023-07-12T13:06:29.973350Z","shell.execute_reply":"2023-07-12T13:06:29.972227Z","shell.execute_reply.started":"2023-07-12T13:06:29.966609Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["\n","# collection = torchmetrics.MetricCollection(\n","#     torchmetrics.Accuracy(task=\"multiclass\" , num_classes = num_classes),\n","# #     torchmetrics.Recall(task=\"multiclass\" , num_classes = num_classes),\n","# #     torchmetrics.Precision(task=\"multiclass\" , num_classes = num_classes),\n","# )\n","\n","collection = torchmetrics.Accuracy(task=\"multiclass\" , num_classes = num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{"_cell_guid":"78de83cd-d08d-4203-a6d1-53b97ce7c6ff","_uuid":"ab2ffe6a-f650-4ef9-89b4-42101e78d298","collapsed":false,"execution":{"iopub.execute_input":"2023-07-12T13:06:30.264253Z","iopub.status.busy":"2023-07-12T13:06:30.263865Z","iopub.status.idle":"2023-07-12T13:06:30.271999Z","shell.execute_reply":"2023-07-12T13:06:30.271055Z","shell.execute_reply.started":"2023-07-12T13:06:30.264220Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import virtusagtn\n","import importlib\n","importlib.reload(virtusagtn) \n","\n","cnngtn = virtusagtn.GTN.DataGTN(loss_fn = nn.CrossEntropyLoss(),\n","                        learnerlist=mylearners,\n","                        num_classes=10, \n","                      batch_size = 4,\n","                      plot_steps = 25,\n","                      metrics = collection,\n","                        device = device)\n","cnngtn.compile(curriculum_loader = train)\n","\n","cnngtn.compileoptimizer(inner_opt=torch.optim.SGD , \n","  inner_opt_params = {'lr':0.01} , \n","  override_params = {'lr':0.02, 'momentum':0.9},\n","  outer_opt = torch.optim.Adam, \n","  outer_opt_params = {'lr':0.01, 'betas':(0.9,0.9)})"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-12T13:06:32.278121Z","iopub.status.busy":"2023-07-12T13:06:32.276137Z","iopub.status.idle":"2023-07-12T13:06:33.657550Z","shell.execute_reply":"2023-07-12T13:06:33.656105Z","shell.execute_reply.started":"2023-07-12T13:06:32.278088Z"},"trusted":true},"outputs":[{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 206.00 MiB (GPU 0; 4.00 GiB total capacity; 9.32 GiB already allocated; 0 bytes free; 9.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m cnngtn\u001b[39m.\u001b[39;49mtrain(val, test, path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgtn\u001b[39;49m\u001b[39m\"\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n","File \u001b[1;32m~\\Desktop\\GTNCode\\src\\virtusagtn\\GTN.py:151\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self, train_loader, test_loader, path, epochs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     _inner_data, _inner_target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_innerloop_data(step)\n\u001b[0;32m    150\u001b[0m     _inner_loss, _inner_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_on_batch(_inner_data, _inner_target, _flearner, _inner_metrics)\n\u001b[1;32m--> 151\u001b[0m     _diffopt\u001b[39m.\u001b[39mstep(_inner_loss)\n\u001b[0;32m    153\u001b[0m _train_loss, _train_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_on_batch(_train_data, _train_target, _flearner, _train_metrics)\n\u001b[0;32m    154\u001b[0m _train_loss\u001b[39m.\u001b[39mbackward()\n","File \u001b[1;32m~\\Desktop\\GTNCode\\src\\virtusagtn\\GTN.py:87\u001b[0m, in \u001b[0;36mGTN.train_on_batch\u001b[1;34m(self, data, labels, model, metric)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m\u001b[39m\u001b[39m''' Returns loss and metric which is derived from input data and labels\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     86\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), labels\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m---> 87\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m     88\u001b[0m metric\u001b[39m.\u001b[39mupdate(output, target)\n\u001b[0;32m     89\u001b[0m inner_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(output, target) \n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\higher\\patch.py:460\u001b[0m, in \u001b[0;36mmake_functional.<locals>._patched_forward\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_patched_forward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    458\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_refill_params_box(params)\n\u001b[1;32m--> 460\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mboxed_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    462\u001b[0m     \u001b[39m# Clean up\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     params_box[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\higher\\patch.py:387\u001b[0m, in \u001b[0;36m_make_functional.<locals>.patched_forward\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m is_RNN \u001b[39mand\u001b[39;00m _torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m    385\u001b[0m     _warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mUserWarning\u001b[39;00m)\n\u001b[1;32m--> 387\u001b[0m \u001b[39mreturn\u001b[39;00m true_forward(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32m~\\Desktop\\GTNCode\\src\\virtusagtn\\Models.py:201\u001b[0m, in \u001b[0;36mLearner.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\higher\\patch.py:387\u001b[0m, in \u001b[0;36m_make_functional.<locals>.patched_forward\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m is_RNN \u001b[39mand\u001b[39;00m _torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m    385\u001b[0m     _warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mUserWarning\u001b[39;00m)\n\u001b[1;32m--> 387\u001b[0m \u001b[39mreturn\u001b[39;00m true_forward(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\higher\\patch.py:387\u001b[0m, in \u001b[0;36m_make_functional.<locals>.patched_forward\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m is_RNN \u001b[39mand\u001b[39;00m _torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m    385\u001b[0m     _warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mUserWarning\u001b[39;00m)\n\u001b[1;32m--> 387\u001b[0m \u001b[39mreturn\u001b[39;00m true_forward(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\higher\\patch.py:387\u001b[0m, in \u001b[0;36m_make_functional.<locals>.patched_forward\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m is_RNN \u001b[39mand\u001b[39;00m _torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m    385\u001b[0m     _warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mUserWarning\u001b[39;00m)\n\u001b[1;32m--> 387\u001b[0m \u001b[39mreturn\u001b[39;00m true_forward(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[0;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    180\u001b[0m     bn_training,\n\u001b[0;32m    181\u001b[0m     exponential_average_factor,\n\u001b[0;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[0;32m    183\u001b[0m )\n","File \u001b[1;32mc:\\Users\\Raunaq\\Desktop\\GTNCode\\env\\gtn\\Lib\\site-packages\\torch\\nn\\functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[0;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[0;32m   2452\u001b[0m )\n","\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 206.00 MiB (GPU 0; 4.00 GiB total capacity; 9.32 GiB already allocated; 0 bytes free; 9.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["df = cnngtn.train(val, test, path=\"gtn\",epochs=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-07-12T13:05:12.909239Z","iopub.status.idle":"2023-07-12T13:05:12.909773Z","shell.execute_reply":"2023-07-12T13:05:12.909537Z","shell.execute_reply.started":"2023-07-12T13:05:12.909514Z"},"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a541aad4-e357-4e5f-9659-e3bd67bfeca3","_uuid":"563bb27a-227f-4f73-b84e-9f0088a87e32","trusted":true},"source":["# __*Initialization*__"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a221a79-a6b9-4318-8158-47cef2b53fa3","_uuid":"6baedaf7-0916-4c20-a477-c8d90e657c9b","collapsed":false,"execution":{"iopub.status.busy":"2023-07-12T13:04:20.974127Z","iopub.status.idle":"2023-07-12T13:04:20.974833Z","shell.execute_reply":"2023-07-12T13:04:20.974597Z","shell.execute_reply.started":"2023-07-12T13:04:20.974574Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# use_teacher = False\n","# use_curriculum = True \n","\n","# params_to_train = []\n","\n","# if use_teacher == True:\n","#     teacher = Teacher().to(device)\n","# #     teacher = nn.DataParallel(teacher, device_ids=list(range(torch.cuda.device_count())))\n","    \n","#     params_to_train += list(teacher.parameters())\n","#     if use_curriculum ==True:\n","#         teacher_noise = nn.Parameter(torch.randn(inner_loop_iterations, batch_size, noise_size), requires_grad=True) \n","#         params_to_train += [teacher_noise]\n","    \n","#     teacher_labels = torch.arange(batch_size) % num_classes                        ## Creating Labels for Generator\n","#     one_hot = nn.functional.one_hot(teacher_labels, num_classes)                                        ## One hot encoding above labels\n","        \n","# else: \n","#     curriculum_data=[]\n","#     curriculum_labels = []\n","\n","#     for i in range(inner_loop_iterations):\n","#         loader = next(train_loader)\n","#         curriculum_data  +=[loader[0]]\n","#         curriculum_labels+=[loader[1]]\n","\n","#     curriculum_data = nn.Parameter(torch.stack((curriculum_data),0).detach(),requires_grad=True)\n","#     curriculum_labels = torch.stack(curriculum_labels,0).detach()\n","#     params_to_train += [curriculum_data]\n","\n","# optimizer_name = \"sgd\"\n","# optimizer_input = {'lr': 0.02, 'momentum':0.9}\n","# # optimizer_input = {'lr': 0.02}\n","\n","    \n","# if optimizer_name == 'adam':\n","# #     ADAM: lr, weight_decay, amsgrad, betas\n","#     default_optimizer = optim.Adam\n","    \n","# if optimizer_name == 'sgd':\n","#     #  SGD: lr, weight_decay, momentum, dampening, nesterov\n","#     default_optimizer = optim.SGD\n","\n","# optim_params = [nn.Parameter(Tensor(x).to(device)) if isinstance(x,list) else nn.Parameter(Tensor([x]).to(device))  for x in optimizer_input.values()]     \n","# # optim_params = nn.Parameter(Tensor(list(optimizer_input.values())).to(device), requires_grad=True)                          ## Parameters for SGD optimizer are also learnt \n","# params_to_train += optim_params\n","\n","\n","# optimizer_teacher = optim.Adam(params_to_train,0.002, [0.9,0.9])                                                           ## Optimizer for Generator\n","# loss_fn = nn.CrossEntropyLoss()                                                                                ## Loss Fn used by the Learner\n","\n","# epochs = 1\n","# plot_steps = 25\n","# batch_exe = 4         \n","# def divide_chunks(l, n):\n","#     for i in range(0, len(l), n): \n","#         yield l[i:i + n]\n","  \n","# batches = list(divide_chunks(list(range(inner_loop_iterations)), batch_exe))\n","\n","# path='./checkpoints'\n","# if not os.path.exists(path):\n","#     os.makedirs(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6748e708-e819-46af-9424-979eb4df4b03","_uuid":"ded14c1e-e675-483f-9862-dd08f0d0627b","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"_cell_guid":"5c086226-0770-42c7-b52c-088fb50c7b86","_uuid":"ef16ebb1-e4f1-45a9-b3b4-8e823375107c","trusted":true},"source":["# __*GTN Training Loop*__"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c818e94-fb7f-4120-a286-8ccfd2a893c9","_uuid":"7723c931-ad9c-4621-aee4-4ed4d2e34600","collapsed":false,"execution":{"iopub.status.busy":"2023-07-12T13:04:20.976089Z","iopub.status.idle":"2023-07-12T13:04:20.976791Z","shell.execute_reply":"2023-07-12T13:04:20.976552Z","shell.execute_reply.started":"2023-07-12T13:04:20.976530Z"},"jupyter":{"outputs_hidden":false},"scrolled":true,"trusted":true},"outputs":[],"source":["# if use_teacher == True:\n","#     curriculum_data=[]\n","#     curriculum_labels=[]\n","#     with torch.no_grad():\n","#         for step in range(inner_loop_iterations):\n","#             curriculum_data += [teacher(teacher_noise[step].to(device),one_hot.to(device)).detach()]\n","#             curriculum_labels += [teacher_labels]\n","#             curriculum_data[step].requires_grads = False\n","#             plot_results(curriculum_data[step])\n","            \n","#         curriculum_data = nn.Parameter(torch.stack((curriculum_data),0).detach(),requires_grad=False)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"59cf85d3-1cf4-4da9-8864-c3571ef5091e","_uuid":"8d6454bf-3f45-4ddf-b449-4ce7fd0c0d16","trusted":true},"source":["# __*Results*__"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66f4757c-4211-4ff6-8cd6-4db6114711e6","_uuid":"78238791-ff37-4596-9201-423cd3db1bb2","collapsed":false,"execution":{"iopub.status.busy":"2023-07-12T13:04:20.978132Z","iopub.status.idle":"2023-07-12T13:04:20.978845Z","shell.execute_reply":"2023-07-12T13:04:20.978620Z","shell.execute_reply.started":"2023-07-12T13:04:20.978587Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# plt.style.use('ggplot')\n","# plt.rcParams[\"figure.figsize\"] = (16,4)\n","\n","\n","# plt.subplot(1,2,1)\n","# plt.plot(range(LIM),gtn[\"Train Loss\"].apply(lambda x:x[-1]),              label=\"GTN\",              linewidth=0.75, color=\"black\")\n","# plt.plot(range(LIM),normaldataset[\"Train Loss\"].apply(lambda x:x[-1]),    label=\"Normal Dataset\",   linewidth=0.75, color=\"red\")\n","# plt.plot(range(LIM),normalcurriculum[\"Train Loss\"].apply(lambda x:x[-1]), label=\"Normal Curriculum\",linewidth=0.75, color=\"green\")\n","# # plt.plot(range(LIM),gtncurriculum[\"Train Loss\"].apply(lambda x:x[-1]),    label=\"GTN Curriculum\",   linewidth=0.75, color=\"blue\")\n","# # plt.plot(range(LIM),gtndataset[\"Train Loss\"].apply(lambda x:x[-1]),       label=\"GTN Dataset\",      linewidth=0.75, color=\"gray\")\n","# plt.title(\"Train Loss\")\n","# plt.legend()\n","# plt.subplot(1,2,2)\n","# plt.plot(range(LIM),gtn[\"Train Accuracy\"].apply(lambda x:x[-1]),              label= \"GTN\",             linewidth=0.75, color= \"black\")\n","# plt.plot(range(LIM),normaldataset[\"Train Accuracy\"].apply(lambda x:x[-1]),    label=\"Normal Dataset\",   linewidth=0.75, color= \"red\")\n","# plt.plot(range(LIM),normalcurriculum[\"Train Accuracy\"].apply(lambda x:x[-1]), label=\"Normal Curriculum\",linewidth=0.75, color= \"green\")\n","# # plt.plot(range(LIM),gtncurriculum[\"Train Accuracy\"].apply(lambda x:x[-1]),    label=\"GTN Curriculum\",   linewidth=0.75, color= \"blue\")\n","# # plt.plot(range(LIM),gtndataset[\"Train Accuracy\"].apply(lambda x:x[-1]),       label=\"GTN Dataset\",      linewidth=0.75, color= \"gray\")\n","\n","# plt.title(\"Train Accuracy\")\n","# plt.legend()\n","# plt.show()\n","\n","# plt.subplot(1,2,1)\n","# plt.plot(range(LIM),gtn[\"Validation Loss\"].apply(lambda x:x[-1]),              label=\"GTN\",              linewidth=0.75, color=\"black\")\n","# plt.plot(range(LIM),normaldataset[\"Validation Loss\"].apply(lambda x:x[-1]),    label=\"Normal Dataset\",   linewidth=0.75, color=\"red\")\n","# plt.plot(range(LIM),normalcurriculum[\"Validation Loss\"].apply(lambda x:x[-1]), label=\"Normal Curriculum\",linewidth=0.75, color=\"green\")\n","# # plt.plot(range(LIM),gtncurriculum[\"Validation Loss\"].apply(lambda x:x[-1]),    label=\"GTN Curriculum\",   linewidth=0.75, color=\"blue\")\n","# # plt.plot(range(LIM),gtndataset[\"Validation Loss\"].apply(lambda x:x[-1]),       label=\"GTN Dataset\",      linewidth=0.75, color=\"gray\")\n","# plt.title(\"Validation Loss\")\n","# plt.legend()\n","# plt.subplot(1,2,2)\n","# plt.plot(range(LIM),gtn[\"Validation Accuracy\"].apply(lambda x:x[-1]),              label= \"GTN\",             linewidth=0.75, color= \"black\")\n","# plt.plot(range(LIM),normaldataset[\"Validation Accuracy\"].apply(lambda x:x[-1]),    label=\"Normal Dataset\",   linewidth=0.75, color= \"red\")\n","# plt.plot(range(LIM),normalcurriculum[\"Validation Accuracy\"].apply(lambda x:x[-1]), label=\"Normal Curriculum\",linewidth=0.75, color= \"green\")\n","# # plt.plot(range(LIM),gtncurriculum[\"Validation Accuracy\"].apply(lambda x:x[-1]),    label=\"GTN Curriculum\",   linewidth=0.75, color= \"blue\")\n","# # plt.plot(range(LIM),gtndataset[\"Validation Accuracy\"].apply(lambda x:x[-1]),       label=\"GTN Dataset\",      linewidth=0.75, color= \"gray\")\n","# plt.title(\"Validation Accuracy\")\n","# plt.legend()\n","# plt.show()\n","\n","# plt.subplot(1,2,1)\n","# plt.plot(range(LIM),gtn[\"Test Loss\"].apply(lambda x:x[-1]),              label=\"GTN\",              linewidth=0.75, color=\"black\")\n","# plt.plot(range(LIM),normaldataset[\"Test Loss\"].apply(lambda x:x[-1]),    label=\"Normal Dataset\",   linewidth=0.75, color=\"red\")\n","# plt.plot(range(LIM),normalcurriculum[\"Test Loss\"].apply(lambda x:x[-1]), label=\"Normal Curriculum\",linewidth=0.75, color=\"green\")\n","# # plt.plot(range(LIM),gtncurriculum[\"Test Loss\"].apply(lambda x:x[-1]),    label=\"GTN Curriculum\",   linewidth=0.75, color=\"blue\")\n","# # plt.plot(range(LIM),gtndataset[\"Test Loss\"].apply(lambda x:x[-1]),       label=\"GTN Dataset\",      linewidth=0.75, color=\"gray\")\n","# plt.title(\"Test Loss\")\n","# plt.legend()\n","# plt.subplot(1,2,2)\n","# plt.plot(range(LIM),gtn[\"Test Accuracy\"].apply(lambda x:x[-1]),              label= \"GTN\",             linewidth=0.75, color= \"black\")\n","# plt.plot(range(LIM),normaldataset[\"Test Accuracy\"].apply(lambda x:x[-1]),    label=\"Normal Dataset\",   linewidth=0.75, color= \"red\")\n","# plt.plot(range(LIM),normalcurriculum[\"Test Accuracy\"].apply(lambda x:x[-1]), label=\"Normal Curriculum\",linewidth=0.75, color= \"green\")\n","# # plt.plot(range(LIM),gtncurriculum[\"Test Accuracy\"].apply(lambda x:x[-1]),    label=\"GTN Curriculum\",   linewidth=0.75, color= \"blue\")\n","# # plt.plot(range(LIM),gtndataset[\"Test Accuracy\"].apply(lambda x:x[-1]),       label=\"GTN Dataset\",      linewidth=0.75, color= \"gray\")\n","# plt.title(\"Test Accuracy\")\n","# plt.legend()\n","# plt.show()\n","\n","# # plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22d48785-c50e-4160-b517-29718c6d6ae6","_uuid":"24a4e58a-6e3d-4a0a-a3be-b5ccd2ee51b5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
